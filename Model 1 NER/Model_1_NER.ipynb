{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the data"
      ],
      "metadata": {
        "id": "9YGSt5t-RGOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries, downloading the model"
      ],
      "metadata": {
        "id": "bCbUUneWRLY4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PouJ6GXRJwav",
        "outputId": "dea28a29-d66d-4db4-d4ce-bba3ff1997bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5.3\n",
            "1.2.2\n",
            "1.22.4\n"
          ]
        }
      ],
      "source": [
        "import pandas\n",
        "import sklearn\n",
        "import numpy\n",
        "import spacy\n",
        "import numpy\n",
        "import sys\n",
        "\n",
        "print(pandas.__version__)\n",
        "print(sklearn.__version__)\n",
        "print(numpy.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Small Russian model for quick test purposes:\n",
        "# !python -m spacy download ru_core_news_sm\n",
        "# nlp = spacy.load('ru_core_news_sm')\n",
        "\n",
        "# Large Russian model:\n",
        "!python -m spacy download ru_core_news_lg\n",
        "nlp = spacy.load('ru_core_news_lg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V77o168KUsg",
        "outputId": "93ee921b-37c5-43fb-a269-cdcdca5458eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-15 16:41:12.193318: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ru-core-news-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_lg-3.5.0/ru_core_news_lg-3.5.0-py3-none-any.whl (513.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m513.4/513.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from ru-core-news-lg==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: pymorphy3>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ru-core-news-lg==3.5.0) (1.2.0)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.5.0) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.10/dist-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.5.0) (0.6.2)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.10/dist-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.5.0) (2.4.417150.4580142)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->ru-core-news-lg==3.5.0) (2.1.2)\n",
            "Installing collected packages: ru-core-news-lg\n",
            "Successfully installed ru-core-news-lg-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making lists and doc objects from csv files"
      ],
      "metadata": {
        "id": "jmR_apKqRQhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's load the training data from a csv file\n",
        "train_set = pandas.read_csv('./train_data.csv', encoding='utf-8')\n",
        "# train_set"
      ],
      "metadata": {
        "id": "7aNaWdrZKDl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = pandas.read_csv('./test_data.csv', encoding='utf-8')\n",
        "# test_set"
      ],
      "metadata": {
        "id": "_aaNuY2gKOQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = train_set['text'].to_list()\n",
        "train_authors = train_set['author'].to_list()\n",
        "\n",
        "test_authors = test_set['author'].to_list()\n",
        "\n",
        "print(len(train_authors), len(test_authors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tap5dtcPKXRW",
        "outputId": "bc47a18c-fa42-4bbd-8817-0f5542a4ef0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_doc_sentences = nlp.pipe(train_sentences)\n",
        "test_doc_sentences = nlp.pipe(test_sentences)"
      ],
      "metadata": {
        "id": "YniZE0rrKeb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entity_types = ['PER', 'LOC', 'ORG']\n",
        "\n",
        "# We are creating a matrix with zero vectors for each review (in training set and test set)\n",
        "train_features_matrix = numpy.zeros((len(train_sentences), 3))\n",
        "print(train_features_matrix.shape)\n",
        "\n",
        "test_features_matrix = numpy.zeros((len(test_sentences), 3))\n",
        "print(test_features_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTA2qXqNKgX6",
        "outputId": "6b608fe6-d5a9-4ed3-913a-c2ffe08445e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 3)\n",
            "(1000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modifying the feature vectors"
      ],
      "metadata": {
        "id": "LliB4utGWJuJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualisation tests"
      ],
      "metadata": {
        "id": "33KX0ePrMsBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisation test:"
      ],
      "metadata": {
        "id": "bA7FexZLMoAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_doc_sentences = nlp.pipe(train_sentences)\n",
        "\n",
        "counter = 0\n",
        "\n",
        "for sentence, author in zip(train_doc_sentences, train_authors):\n",
        "    print(sentence)\n",
        "    NEs_in_sentence = [entity.label_ for entity in sentence.ents]\n",
        "    print(NEs_in_sentence)\n",
        "    for entity_type in entity_types:\n",
        "      if entity_type in NEs_in_sentence:\n",
        "        print(entity_type)\n",
        "\n",
        "    counter +=1\n",
        "    print('The author is: ', author)\n",
        "    if counter == 10:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H-R8OqLLxgm",
        "outputId": "ce521a94-defe-4905-bceb-52de3eb2c435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Но каково же было мое изумление, когда Наташа с первых же слов остановила меня и сказала, что нечего ее утешать, что она уже пять дней, как знает про это..     – Боже мой!\n",
            "['PER']\n",
            "PER\n",
            "The author is:  Dostoevsky\n",
            "— закричали в толпе.. — Давай совет кошевой!\n",
            "[]\n",
            "The author is:  Gogol\n",
            "И всё, бывало, извиняется.\n",
            "[]\n",
            "The author is:  Chekhov\n",
            "Живу-ут!.\n",
            "[]\n",
            "The author is:  Chekhov\n",
            "Там воду освятим: они скорее выздоровеют; и я теперь здоров: у меня болел глаз, а теперь смотрю в оба»..      — А мне говорили военные люди, — сказал Пьер, — что в городе никак нельзя сражаться и что позиция….\n",
            "['PER']\n",
            "PER\n",
            "The author is:  Tolstoy\n",
            "Ее-то огромное состояние у него осталось теперь, а его собственное, родовое, перешло меньшому брату, князю Ивану, который теперь обер-гоф-кафермейстер (он назвал что-то в этом роде) и был министром.. .\n",
            "['PER']\n",
            "PER\n",
            "The author is:  Tolstoy\n",
            "— сказал он.\n",
            "[]\n",
            "The author is:  Tolstoy\n",
            "Он вступил на площадь не без какой-то невольной боязни, точно как будто сердце его предчувствовало что-то недоброе.\n",
            "[]\n",
            "The author is:  Gogol\n",
            "Господи, столько во всем этом жизни, поэзии, смысла, что камень бы тронулся, а я... я глуп и нелеп!».\n",
            "[]\n",
            "The author is:  Chekhov\n",
            "Уходят..       Входит Чебутыкин..       Маша.\n",
            "['PER', 'PER']\n",
            "PER\n",
            "The author is:  Chekhov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisation Test 2:"
      ],
      "metadata": {
        "id": "w08xzYNGRQti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process a text\n",
        "train_features_matrix = numpy.zeros((len(train_sentences), 3))\n",
        "train_doc_sentences = nlp.pipe(train_sentences)\n",
        "\n",
        "counter = 0\n",
        "# loop over each review, label and feature vector at the same time (zip)\n",
        "for sentence, author, feature_vector in zip(train_doc_sentences, train_authors, train_features_matrix):\n",
        "    print('Author:', author)\n",
        "    print(sentence)\n",
        "    NEs_in_sentence = [entity.label_ for entity in sentence.ents]\n",
        "    #print(tokens_list)\n",
        "    for entity_type in entity_types:\n",
        "      if entity_type in NEs_in_sentence:\n",
        "        entity_id = entity_types.index(entity_type)\n",
        "        print(entity_type)\n",
        "        print(entity_id)\n",
        "        feature_vector[entity_id] = 1\n",
        "        print(feature_vector)\n",
        "    print()\n",
        "    counter +=1\n",
        "    if counter == 10:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DZ56u6DQsu8",
        "outputId": "08ab3e36-e4af-4891-b9c8-aa64229f27be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Dostoevsky\n",
            "Но каково же было мое изумление, когда Наташа с первых же слов остановила меня и сказала, что нечего ее утешать, что она уже пять дней, как знает про это..     – Боже мой!\n",
            "PER\n",
            "0\n",
            "[1. 0. 0.]\n",
            "\n",
            "Author: Gogol\n",
            "— закричали в толпе.. — Давай совет кошевой!\n",
            "\n",
            "Author: Chekhov\n",
            "И всё, бывало, извиняется.\n",
            "\n",
            "Author: Chekhov\n",
            "Живу-ут!.\n",
            "\n",
            "Author: Tolstoy\n",
            "Там воду освятим: они скорее выздоровеют; и я теперь здоров: у меня болел глаз, а теперь смотрю в оба»..      — А мне говорили военные люди, — сказал Пьер, — что в городе никак нельзя сражаться и что позиция….\n",
            "PER\n",
            "0\n",
            "[1. 0. 0.]\n",
            "\n",
            "Author: Tolstoy\n",
            "Ее-то огромное состояние у него осталось теперь, а его собственное, родовое, перешло меньшому брату, князю Ивану, который теперь обер-гоф-кафермейстер (он назвал что-то в этом роде) и был министром.. .\n",
            "PER\n",
            "0\n",
            "[1. 0. 0.]\n",
            "\n",
            "Author: Tolstoy\n",
            "— сказал он.\n",
            "\n",
            "Author: Gogol\n",
            "Он вступил на площадь не без какой-то невольной боязни, точно как будто сердце его предчувствовало что-то недоброе.\n",
            "\n",
            "Author: Chekhov\n",
            "Господи, столько во всем этом жизни, поэзии, смысла, что камень бы тронулся, а я... я глуп и нелеп!».\n",
            "\n",
            "Author: Chekhov\n",
            "Уходят..       Входит Чебутыкин..       Маша.\n",
            "PER\n",
            "0\n",
            "[1. 0. 0.]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Writing a function for feature vector modification"
      ],
      "metadata": {
        "id": "q6ZINrDZWXFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_feature_vectors(doc_sentences, features_matrix):\n",
        "  for sentence, feature_vector in zip(doc_sentences, features_matrix):\n",
        "      NEs_in_sentence = [entity.label_ for entity in sentence.ents]\n",
        "      for entity_type in entity_types:\n",
        "        if entity_type in NEs_in_sentence:\n",
        "          entity_id = entity_types.index(entity_type)\n",
        "          feature_vector[entity_id] = 1\n",
        "  return features_matrix"
      ],
      "metadata": {
        "id": "PJYD3naCWdpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_matrix = numpy.zeros((len(train_sentences), 3))\n",
        "train_doc_sentences = nlp.pipe(train_sentences)\n",
        "\n",
        "train_features_matrix_final = modify_feature_vectors(train_doc_sentences, train_features_matrix)"
      ],
      "metadata": {
        "id": "ChPSkQqzXvB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "W9vhUXBXUi4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "\n",
        "lr.fit(train_features_matrix_final, train_authors)\n",
        "\n",
        "print(lr.classes_)\n",
        "print(lr.get_params())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4USrEQh3U4O2",
        "outputId": "18b77f9f-05f5-4185-fd28-fe1debeaad05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Chekhov' 'Dostoevsky' 'Gogol' 'Tolstoy']\n",
            "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modify the test set feature vectors"
      ],
      "metadata": {
        "id": "-R9cysrwcMIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_doc_sentences = nlp.pipe(test_sentences)\n",
        "test_features_matrix = numpy.zeros((len(test_sentences), 3))\n",
        "\n",
        "test_features_matrix_final = modify_feature_vectors(test_doc_sentences, test_features_matrix)"
      ],
      "metadata": {
        "id": "TxX35ZmTcTCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making predictions"
      ],
      "metadata": {
        "id": "4rd-kqW9cxiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(i):\n",
        "    print(test_sentences[i])\n",
        "    # print the features of the index\n",
        "    print(test_features_matrix_final[i])\n",
        "    # print all entity types\n",
        "    print(entity_types)\n",
        "    # print the correct label of the index\n",
        "    print(test_authors[i])\n",
        "\n",
        "    print()\n",
        "    print(\"Prediction:\")\n",
        "    # print the prediction for the features of this index\n",
        "    print(lr.predict([test_features_matrix_final[i]]))\n",
        "    # print the probabilities for each label predictions\n",
        "    print(lr.predict_proba([test_features_matrix_final[i]]))\n",
        "    print()"
      ],
      "metadata": {
        "id": "UgUJ1LFTc2Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(23)\n",
        "predict(24)\n",
        "predict(25)\n",
        "predict(26)\n",
        "predict(27)\n",
        "predict(28)"
      ],
      "metadata": {
        "id": "SKDvgZKddagW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we provide all the features as inoput to our model\n",
        "test_predictions_ner = lr.predict(test_features_matrix_final)\n",
        "\n",
        "for p, r in zip(test_predictions_ner[:10], test_authors[:10]):\n",
        "    if p == r:\n",
        "        result = \"Correct\"\n",
        "    else:\n",
        "        result = \"Incorrect\"\n",
        "    print(f\"{p} ({result}:{r})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJZ_aSf0hj9B",
        "outputId": "6ffb030c-5dd6-4ea0-9af5-42f32d6a9922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chekhov(Incorrect:Dostoevsky)\n",
            "Dostoevsky(Incorrect:Chekhov)\n",
            "Dostoevsky(Incorrect:Gogol)\n",
            "Dostoevsky(Correct:Dostoevsky)\n",
            "Dostoevsky(Incorrect:Gogol)\n",
            "Tolstoy(Incorrect:Dostoevsky)\n",
            "Dostoevsky(Correct:Dostoevsky)\n",
            "Dostoevsky(Incorrect:Chekhov)\n",
            "Chekhov(Incorrect:Dostoevsky)\n",
            "Dostoevsky(Correct:Dostoevsky)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysing the model"
      ],
      "metadata": {
        "id": "qNCZdlkieckh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for label, coefs, intercept in zip(lr.classes_, lr.coef_, lr.intercept_):\n",
        "    print(label)\n",
        "    for t, c in zip(entity_types, coefs):\n",
        "        print(t, c)\n",
        "    print(\"INTERCEPT:\", intercept)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJuFYPgXegUV",
        "outputId": "d76a3c93-19ca-4c17-ce50-f10c7df8ff3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chekhov\n",
            "PER 0.1561336751358554\n",
            "LOC -0.21764533083370355\n",
            "ORG -0.23611650129519218\n",
            "INTERCEPT: -0.030575998134737735\n",
            "\n",
            "Dostoevsky\n",
            "PER -0.17658652419566542\n",
            "LOC -0.32450439653856056\n",
            "ORG 0.08049482072985621\n",
            "INTERCEPT: 0.06364122153367807\n",
            "\n",
            "Gogol\n",
            "PER -0.12414701627264657\n",
            "LOC 0.08812516959084483\n",
            "ORG -0.43733717051896115\n",
            "INTERCEPT: 0.037970579292936395\n",
            "\n",
            "Tolstoy\n",
            "PER 0.14459986533245467\n",
            "LOC 0.45402455778142037\n",
            "ORG 0.5929588510842979\n",
            "INTERCEPT: -0.07103580269125283\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the model"
      ],
      "metadata": {
        "id": "v8Ah8SO9e-ez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save to file in the current working directory\n",
        "pkl_filename = \"logreg_NER.pkl\"\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(lr, file)"
      ],
      "metadata": {
        "id": "du0IK-2WfBxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the model"
      ],
      "metadata": {
        "id": "vky2N4dMga-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dummy model"
      ],
      "metadata": {
        "id": "9UU99s-Bgh6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "dummy_predictions = ['Dostoevsky'] * len(test_sentences)\n",
        "print(len(dummy_predictions))\n",
        "\n",
        "# Calculate the accuracy of these \"dummy predictions\"\n",
        "acc_dummy = accuracy_score(test_authors, dummy_predictions)\n",
        "print('The accuracy is:', acc_dummy)\n",
        "print()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_authors, dummy_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7DTkls8ggHP",
        "outputId": "004b2ca7-330b-474b-8cc0-b5cde26efe45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "The accuracy is: 0.25\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Chekhov       0.00      0.00      0.00       250\n",
            "  Dostoevsky       0.25      1.00      0.40       250\n",
            "       Gogol       0.00      0.00      0.00       250\n",
            "     Tolstoy       0.00      0.00      0.00       250\n",
            "\n",
            "    accuracy                           0.25      1000\n",
            "   macro avg       0.06      0.25      0.10      1000\n",
            "weighted avg       0.06      0.25      0.10      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NER Model"
      ],
      "metadata": {
        "id": "huhrv8PpiiLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy:')\n",
        "\n",
        "acc = accuracy_score(test_authors, test_predictions_ner)\n",
        "print(acc)\n",
        "corr_count = accuracy_score(test_authors, test_predictions_ner, normalize=False)\n",
        "total_count = len(test_authors)\n",
        "\n",
        "print(\"Total reviews: \" + str(str(total_count)))\n",
        "print(\"Total correct predictions:\" + str(corr_count))\n",
        "corr_ratio = corr_count / total_count\n",
        "print(\"Correct ratio:\" + str(corr_ratio))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtqaURV7hGc3",
        "outputId": "66a393ac-d384-4022-f9dc-72b37d8a90d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:\n",
            "0.261\n",
            "Total reviews: 1000\n",
            "Total correct predictions:261\n",
            "Correct ratio:0.261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_authors, test_predictions_ner))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3rFkmxRjMFU",
        "outputId": "078993f5-403e-4ee5-b829-4edfe28c5a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Chekhov       0.30      0.30      0.30       250\n",
            "  Dostoevsky       0.24      0.68      0.35       250\n",
            "       Gogol       0.00      0.00      0.00       250\n",
            "     Tolstoy       0.36      0.06      0.11       250\n",
            "\n",
            "    accuracy                           0.26      1000\n",
            "   macro avg       0.23      0.26      0.19      1000\n",
            "weighted avg       0.23      0.26      0.19      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}
