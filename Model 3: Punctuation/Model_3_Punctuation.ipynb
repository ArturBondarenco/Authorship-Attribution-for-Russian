{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the data"
      ],
      "metadata": {
        "id": "p35nW_CwZtOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries, downloading the model"
      ],
      "metadata": {
        "id": "JK3G0mhrZ0OW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE8srEnJZiKo",
        "outputId": "309c4259-3cf7-4cb8-9c18-5f5ef4bc418f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5.3\n",
            "1.2.2\n",
            "1.22.4\n"
          ]
        }
      ],
      "source": [
        "import pandas\n",
        "import sklearn\n",
        "import numpy\n",
        "import spacy\n",
        "import string\n",
        "import sys\n",
        "import pickle\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(pandas.__version__)\n",
        "print(sklearn.__version__)\n",
        "print(numpy.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Small Russian model:\n",
        "# !python -m spacy download ru_core_news_sm\n",
        "# nlp = spacy.load('ru_core_news_sm')\n",
        "\n",
        "# Large Russian model:\n",
        "!python -m spacy download ru_core_news_lg\n",
        "nlp = spacy.load('ru_core_news_lg')"
      ],
      "metadata": {
        "id": "f6pB9SS2aBIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making lists and doc objects from csv files"
      ],
      "metadata": {
        "id": "f6U4it85aIYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's load the training data from a csv file\n",
        "train_set = pandas.read_csv('./train_data.csv', encoding='utf-8')\n",
        "# train_set"
      ],
      "metadata": {
        "id": "PZ2AeqfoaPAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = pandas.read_csv('./test_data.csv', encoding='utf-8')\n",
        "# test_set"
      ],
      "metadata": {
        "id": "yafWa-phaSFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = train_set['text'].to_list()\n",
        "train_authors = train_set['author'].to_list()\n",
        "\n",
        "test_sentences = test_set['text'].to_list()\n",
        "test_authors = test_set['author'].to_list()\n",
        "\n",
        "print(len(train_authors), len(test_authors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWaAMKctaUP0",
        "outputId": "1b67a840-a1af-4a4c-99dc-9b1b0b204f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_doc_sentences = nlp.pipe(train_sentences)\n",
        "test_doc_sentences = nlp.pipe(test_sentences)"
      ],
      "metadata": {
        "id": "L4QPWcGZaacu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizing the text, replacing \"...\" with \"…\""
      ],
      "metadata": {
        "id": "vAKQnqvcaeJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_ellipsis(sentences):\n",
        "  updated_sentences = []\n",
        "  for sentence in sentences:\n",
        "    updated_sentence = sentence.replace(\"...\", \"…\")\n",
        "    updated_sentences.append(updated_sentence)\n",
        "  return updated_sentences\n",
        "\n",
        "train_sentences = replace_ellipsis(train_sentences)\n",
        "test_sentences = replace_ellipsis(test_sentences)"
      ],
      "metadata": {
        "id": "puz57zdzavDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding additional punctuation marks into string.punctuation"
      ],
      "metadata": {
        "id": "RNDywhgMbnZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_punctuation_string = \"—«»–‹›…\" + string.punctuation\n",
        "print(new_punctuation_string)\n",
        "print(len(new_punctuation_string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK8FvrtSbRhL",
        "outputId": "3b5bb760-47bb-42c7-c71d-8232ea46e908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "—«»–‹›…!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We are creating a matrix with zero vectors for each review (in training set and test set)\n",
        "train_features_matrix = numpy.zeros((len(train_sentences), len(new_punctuation_string)))\n",
        "print(train_features_matrix.shape)\n",
        "\n",
        "test_features_matrix = numpy.zeros((len(test_sentences), len(new_punctuation_string)))\n",
        "print(test_features_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6r5CJtgb_T6",
        "outputId": "24b8275b-e9de-4c93-9f20-7146612830b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 39)\n",
            "(1000, 39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modifying the feature vectors"
      ],
      "metadata": {
        "id": "8kb6uKtmcSc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualisation tests"
      ],
      "metadata": {
        "id": "drUppP65co7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "\n",
        "for sentence, author in zip(train_sentences, train_authors):\n",
        "    print('Author:', author)\n",
        "    print(sentence)\n",
        "    for char in sentence:\n",
        "      if char in new_punctuation_string:\n",
        "        print(char)\n",
        "        char_id = new_punctuation_string.index(char)\n",
        "        print(char_id)\n",
        "    counter +=1\n",
        "    if counter == 2:\n",
        "      break\n",
        "        # sys.exit()"
      ],
      "metadata": {
        "id": "QVHzIpJLctsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fbde1cd-aae2-45f6-8daf-0bb54e8feedc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Dostoevsky\n",
            "Но каково же было мое изумление, когда Наташа с первых же слов остановила меня и сказала, что нечего ее утешать, что она уже пять дней, как знает про это..     – Боже мой!\n",
            ",\n",
            "18\n",
            ",\n",
            "18\n",
            ",\n",
            "18\n",
            ",\n",
            "18\n",
            ".\n",
            "20\n",
            ".\n",
            "20\n",
            "–\n",
            "3\n",
            "!\n",
            "7\n",
            "Author: Gogol\n",
            "— закричали в толпе.. — Давай совет кошевой!\n",
            "—\n",
            "0\n",
            ".\n",
            "20\n",
            ".\n",
            "20\n",
            "—\n",
            "0\n",
            "!\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisation test 2:"
      ],
      "metadata": {
        "id": "4a3qCfIshpYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "\n",
        "for sentence, author, feature_vector in zip(train_sentences, train_authors, train_features_matrix):\n",
        "    print('Author:', author)\n",
        "    print(sentence)\n",
        "    for char in sentence:\n",
        "      if char in new_punctuation_string:\n",
        "        print(char)\n",
        "        char_id = new_punctuation_string.index(char)\n",
        "        print(char_id)\n",
        "        feature_vector[char_id] = 1\n",
        "        print(feature_vector.tolist())\n",
        "        # sys.exit()\n",
        "    counter +=1\n",
        "    if counter == 2:\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9rgyMTMfYKK",
        "outputId": "24d5a052-ab2c-49dd-91be-ee219f545f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Dostoevsky\n",
            "Но каково же было мое изумление, когда Наташа с первых же слов остановила меня и сказала, что нечего ее утешать, что она уже пять дней, как знает про это..     – Боже мой!\n",
            ",\n",
            "18\n",
            "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            ",\n",
            "18\n",
            "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            ",\n",
            "18\n",
            "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            ",\n",
            "18\n",
            "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            ".\n",
            "20\n",
            "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            ".\n",
            "20\n",
            "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "–\n",
            "3\n",
            "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "!\n",
            "7\n",
            "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Author: Gogol\n",
            "— закричали в толпе.. — Давай совет кошевой!\n",
            "—\n",
            "0\n",
            "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            ".\n",
            "20\n",
            "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            ".\n",
            "20\n",
            "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "—\n",
            "0\n",
            "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "!\n",
            "7\n",
            "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Writing a function for vector modification"
      ],
      "metadata": {
        "id": "NbtE-uGEhxXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_feature_vectors(sentences, features_matrix):\n",
        "  for sentence, feature_vector in zip(sentences, features_matrix):\n",
        "    for char in sentence:\n",
        "      if char in new_punctuation_string:\n",
        "        char_id = new_punctuation_string.index(char)\n",
        "        feature_vector[char_id] = 1\n",
        "  return features_matrix"
      ],
      "metadata": {
        "id": "8Tjxje2qhE0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_matrix = numpy.zeros((len(train_sentences), len(new_punctuation_string)))\n",
        "train_features_matrix_final = modify_feature_vectors(train_sentences, train_features_matrix)\n",
        "\n",
        "print(train_features_matrix_final[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwLH9P3xiYZK",
        "outputId": "24121fa7-e9a1-4b4d-c865-71d0eefd28c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "n2s_RwI9ijnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_punct = LogisticRegression()\n",
        "\n",
        "# Train the model on the data, storing the information learned from the dat`a\n",
        "# Model is learning the relationship between digits (x_train) and labels (y_train)\n",
        "lr_punct.fit(train_features_matrix_final, train_authors)\n",
        "\n",
        "print(lr_punct.classes_)\n",
        "print(lr_punct.get_params())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMnGm_j4imTQ",
        "outputId": "ecfbcff3-7bcb-421c-d870-e458e43798f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Chekhov' 'Dostoevsky' 'Gogol' 'Tolstoy']\n",
            "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modifying the test set feature vectors"
      ],
      "metadata": {
        "id": "dQVxayAWi77X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_features_matrix = numpy.zeros((len(test_sentences), len(new_punctuation_string)))\n",
        "test_features_matrix_final = modify_feature_vectors(test_sentences, test_features_matrix)\n",
        "\n",
        "print(test_features_matrix_final[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRHQU7Aci2RY",
        "outputId": "613cd9e5-6d95-49e7-e096-ca8ee9796345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making predictions"
      ],
      "metadata": {
        "id": "hbU0YxMGjTqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(i):\n",
        "    print(test_sentences[i])\n",
        "    # print the features of the index\n",
        "    print(test_features_matrix_final[i])\n",
        "    # print the correct label of the index\n",
        "    print(test_authors[i])\n",
        "\n",
        "    print()\n",
        "    print(\"Prediction:\")\n",
        "    # print the prediction for the features of this index\n",
        "    print(lr_punct.predict([test_features_matrix_final[i]]))\n",
        "    # print the probabilities for each label predictions\n",
        "    print(lr_punct.predict_proba([test_features_matrix_final[i]]))\n",
        "    print()"
      ],
      "metadata": {
        "id": "rGbNkiYOjWUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(0)\n",
        "predict(1)\n",
        "predict(2)\n",
        "predict(3)\n",
        "predict(4)\n",
        "predict(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoBN8jdmjph0",
        "outputId": "c043b4cf-4e34-4b10-826e-b2efd1f81092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Фома Фомич, говорю, разве это возможное дело?\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Dostoevsky\n",
            "\n",
            "Prediction:\n",
            "['Dostoevsky']\n",
            "[[0.01173762 0.44792683 0.13174912 0.40858642]]\n",
            "\n",
            "Пора бы уже домой.\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Chekhov\n",
            "\n",
            "Prediction:\n",
            "['Tolstoy']\n",
            "[[0.24520035 0.21544688 0.24942938 0.28992339]]\n",
            "\n",
            "А казаки все до одного прощались, зная, что много будет работы тем и другим, но не повершили, однако ж, тотчас разлучиться, а повершили дождаться темной ночной поры, чтоб не дать неприятелю увидеть убыль в казацком войске.\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Gogol\n",
            "\n",
            "Prediction:\n",
            "['Tolstoy']\n",
            "[[0.20652203 0.25246681 0.24582304 0.29518812]]\n",
            "\n",
            "Вдруг слезы градом у обоих из глаз, дрогнули руки.\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Dostoevsky\n",
            "\n",
            "Prediction:\n",
            "['Tolstoy']\n",
            "[[0.20652203 0.25246681 0.24582304 0.29518812]]\n",
            "\n",
            "Но художник видел в этом нежном личике одну только заманчивую для кисти почти фарфоровую проэрачность тела, увлекательную легкую томность, тонкую светлую шейку и аристократическую легкостъ стана.\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Gogol\n",
            "\n",
            "Prediction:\n",
            "['Tolstoy']\n",
            "[[0.20652203 0.25246681 0.24582304 0.29518812]]\n",
            "\n",
            "Когда я в Берлине получил оттуда несколько маленьких писем, которые они уже успели мне написать, то тут только я и понял, как их любил.\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Dostoevsky\n",
            "\n",
            "Prediction:\n",
            "['Tolstoy']\n",
            "[[0.20652203 0.25246681 0.24582304 0.29518812]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions_punct = lr_punct.predict(test_features_matrix_final)\n",
        "\n",
        "for p, r in zip(test_predictions_punct[:10], test_authors[:10]):\n",
        "    if p == r:\n",
        "        result = \"Correct\"\n",
        "    else:\n",
        "        result = \"Incorrect\"\n",
        "    print(f\"{p} ({result}:{r})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z-SInc-jrkQ",
        "outputId": "e17a9782-5c57-4344-c6da-c8344849de02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dostoevsky(Correct:Dostoevsky)\n",
            "Tolstoy(Incorrect:Chekhov)\n",
            "Tolstoy(Incorrect:Gogol)\n",
            "Tolstoy(Incorrect:Dostoevsky)\n",
            "Tolstoy(Incorrect:Gogol)\n",
            "Tolstoy(Incorrect:Dostoevsky)\n",
            "Tolstoy(Incorrect:Dostoevsky)\n",
            "Chekhov(Correct:Chekhov)\n",
            "Dostoevsky(Correct:Dostoevsky)\n",
            "Gogol(Incorrect:Dostoevsky)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the model"
      ],
      "metadata": {
        "id": "5s_QoQDwl6B0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to file in the current working directory\n",
        "pkl_filename = \"logreg_punkt.pkl\"\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(lr_punct, file)"
      ],
      "metadata": {
        "id": "suAFzPrvl13s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the model"
      ],
      "metadata": {
        "id": "Ke0hkCFsmFxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dummy Model"
      ],
      "metadata": {
        "id": "WdvY5Co1mL2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_predictions = ['Dostoevsky'] * len(test_sentences)\n",
        "print(len(dummy_predictions))\n",
        "\n",
        "# Calculate the accuracy of these \"dummy predictions\"\n",
        "acc_dummy = accuracy_score(test_authors, dummy_predictions)\n",
        "print(f'The accuracy is: {acc_dummy}')\n",
        "print()\n",
        "\n",
        "print(classification_report(test_authors, dummy_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRT4shq6mKCy",
        "outputId": "bbd74f23-7b25-44a4-c035-6ab90c98719f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "The accuracy is: 0.25\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Chekhov       0.00      0.00      0.00       250\n",
            "  Dostoevsky       0.25      1.00      0.40       250\n",
            "       Gogol       0.00      0.00      0.00       250\n",
            "     Tolstoy       0.00      0.00      0.00       250\n",
            "\n",
            "    accuracy                           0.25      1000\n",
            "   macro avg       0.06      0.25      0.10      1000\n",
            "weighted avg       0.06      0.25      0.10      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Punctuation model"
      ],
      "metadata": {
        "id": "A5gbCuWpmVJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy:')\n",
        "\n",
        "acc = accuracy_score(test_authors, test_predictions_punct)\n",
        "print(acc)\n",
        "corr_count = accuracy_score(test_authors, test_predictions_punct, normalize=False)\n",
        "total_count = len(test_authors)\n",
        "\n",
        "print(f'Total reviews: {str(total_count)}')\n",
        "print(f'Total correct predictions: {str(corr_count)}')\n",
        "corr_ratio = corr_count / total_count\n",
        "print(f'Correct ratio: {str(corr_ratio)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUMJewiBmR-G",
        "outputId": "c5b2fa31-b838-497b-8c8b-49cba9f0148d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:\n",
            "0.371\n",
            "Total reviews: 1000\n",
            "Total correct predictions:371\n",
            "Correct ratio:0.371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_authors, test_predictions_punct))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In01xGOrmfH-",
        "outputId": "f8f11131-21c7-47d2-e9eb-46b2ae81571f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Chekhov       0.53      0.36      0.43       250\n",
            "  Dostoevsky       0.35      0.20      0.26       250\n",
            "       Gogol       0.37      0.28      0.32       250\n",
            "     Tolstoy       0.32      0.64      0.43       250\n",
            "\n",
            "    accuracy                           0.37      1000\n",
            "   macro avg       0.39      0.37      0.36      1000\n",
            "weighted avg       0.39      0.37      0.36      1000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}